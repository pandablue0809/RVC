{
    "inference.save.button": "Save Options",
    "inference.refresh_data.button": "Refresh Data",
    "inference.clear_data.button": "Unload Model",
    "inference.load_model.button": "Load Model",
    "inference.one_click.button": "1-Click VC",
    "inference.song.selectbox": "Select a song file",
    "inference.voice.selectbox": "Select a voice model",

    "inference.split_vocals": "Extract Vocals",
    "inference.split_vocals.expander": "Extract Vocals Options",
    "inference.preprocess_model": "Choose a preprocessing model (sequential)",
    "inference.model_paths": "Choose a vocal extraction model (parallel)",
    "inference.postprocess_model": "Chose a postprocessing model (sequential)",
    "inference.device": "Device",
    "inference.merge_type": "Merge Type",
    "inference.agg": "Aggressiveness in isolating vocals",
    "inference.use_cache": "Reduce future processing time by saving results to disk",

    "inference.convert_vocals": "Change Vocals",
    "inference.convert_vocals.expander": "Change Vocals Options",
    "inference.convert_vocals.expander.form_submit_button": "Save Options",
    
    "inference.f0_up_key": "Recommended +7 or +12 key for male to female conversion, and -12 or -5 key for female to male conversion. If the sound range goes too far and the voice is distorted, you can also adjust it to the appropriate range by yourself.",
    "inference.f0_method": "Select the pitch extraction algorithm ('crepe': better quality but GPU intensive, 'rmvpe': fast and best quality, and little GPU requirement, others: use them if you really want to...)",
    "inference.f0_autotune": "Enable autotuning of extracted pitch",
    "inference.filter_radius": "If >=3: apply median filtering to the harvested pitch results. The value represents the filter radius and can reduce breathiness.",
    "inference.index_rate": "Search feature ratio (controls accent strength, too high has artifacting):",
    "inference.resample_sr": "Resample the output audio in post-processing to the final sample rate. Set to 0 for no resampling:",
    "inference.rms_mix_rate": "Adjust the volume envelope scaling. Closer to 0, the more it mimicks the volume of the original vocals. Can help mask noise and make volume sound more natural when set relatively low. Closer to 1 will be more of a consistently loud volume:",
    "inference.protect": "Protect voiceless consonants and breath sounds to prevent artifacts such as tearing in electronic music. Set to 0.5 to disable. Decrease the value to increase protection, but it may reduce indexing accuracy:",
    
    "inference.download.button": "Download Song",

    "training.preprocess_data.title": "Process Data",
    "training.preprocess_data.text": "Step 1: Fill in the experimental configuration. Experimental data is stored in the 'logs' folder, with each experiment having a separate folder. Manually enter the experiment name path, which contains the experimental configuration, logs, and trained model files.",
    "training.exp_dir": "Enter the voice model name:",
    "training.sr": "Target sample rate:",
    "training.if_f0": "Whether the model has pitch guidance (required for singing, optional for speech):",
    "training.version": "Version:",
    "training.device": "Device:",
    "training.n_threads": "Number of CPU processes used for pitch extraction and data processing:",
    "training.extract_features.title": "Extract Features",
    "training.extract_features.text": "Step 2: Automatically traverse all files in the training folder that can be decoded into audio and perform slice normalization. Generates 2 wav folders in the experiment directory. Currently, only single-singer/speaker training is supported.",
    "training.preprocess_data.trainset_dir": "Enter the path of the training folder:",
    "training.sid": "Please specify the speaker/singer ID:",
    "training.preprocess_data.submit": "1. Process data",
    "training.train_model.gpus": "Enter the GPU index(es) separated by '-', e.g., 0-1-2 to use GPU 0, 1, and 2:",
    "training.f0method": "Select the pitch extraction algorithm ('crepe': better quality but GPU intensive, 'rmvpe': best quality, and little GPU requirement)",
    "training.extract_features.submit": "2. Feature extraction",
    "training.train_model.title": "Train Model",
    "training.train_model.text": "Step 3: Fill in the training settings and start training the model and index",
    "training.save_every_epoch": "Save frequency (save_every_epoch):",
    "training.total_epoch": "Total training epochs (total_epoch):",
    "training.batch_size": "Batch size per GPU:",
    "training.if_save_latest": "Save only the latest '.ckpt' file to save disk space",
    "training.if_save_best": "Save only the best model (lowest overall loss) to the 'logs' folder",
    "training.if_cache_gpu": "Cache all training sets to GPU memory. Caching small datasets (less than 10 minutes) can speed up training, but caching large datasets will consume a lot of GPU memory and may not provide much speed improvement",
    "training.if_save_every_weights": "Save a small final model to the 'logs' folder at each save point",
    "training.pretrained_G": "Load pre-trained base model G path:",
    "training.pretrained_D": "Load pre-trained base model D path:",
    "training.train_model.submit": "3. Train model",
    "training.train_index.submit": "4. Train feature index",
    "training.train_speaker.submit": "Train Optional Speaker Embedding",
    "training.one_click": "One-click training",

    "process.pids": "Active Processes",
    "process.kill_all_pids": "Close All Processes",
    "process.kill_one_pid": "Stop",

        "tts.inference": "Text to Speech",
        "tts.options": "TTS Options",
        "tts.model.selectbox": "TTS Models",
    "ckpt处理": "ckpt Processing",
    "模型融合, 可用于测试音色融合": "Model fusion, can be used to test timbre fusion",
    "A模型路径": "Path to Model A:",
    "B模型路径": "Path to Model B:",
    "A模型权重": "Weight (w) for Model A:",
    "模型是否带音高指导": "Whether the model has pitch guidance:",
    "要置入的模型信息": "Model information to be placed:",
    "保存的模型名不带后缀": "Saved model name (without extension):",
    "模型版本型号": "Model architecture version:",
    "融合": "Fusion",
    "修改模型信息(仅支持weights文件夹下提取的小模型文件)": "Modify model information (only supported for small model files extracted from the 'weights' folder)",
    "模型路径": "Path to Model:",
    "要改的模型信息": "Model information to be modified:",
    "保存的文件名, 默认空为和源文件同名": "Save file name (default: same as the source file):",
    "修改": "Modify",
    "查看模型信息(仅支持weights文件夹下提取的小模型文件)": "View model information (only supported for small model files extracted from the 'weights' folder)",
    "查看": "View",
    "模型提取(输入logs文件夹下大文件模型路径),适用于训一半不想训了模型没有自动提取保存小文件模型,或者想测试中间模型的情况": "Model extraction (enter the path of the large file model under the 'logs' folder). This is useful if you want to stop training halfway and manually extract and save a small model file, or if you want to test an intermediate model:",
    "保存名": "Save name:",
    "模型是否带音高指导,1是0否": "Whether the model has pitch guidance (1: yes, 0: no):",
    "提取": "Extract",
    "Onnx导出": "Export Onnx",
    "RVC模型路径": "RVC Model Path:",
    "Onnx输出路径": "Onnx Export Path:",
    "导出Onnx模型": "Export Onnx Model",
    "常见问题解答": "FAQ (Frequently Asked Questions)",
    "招募音高曲线前端编辑器": "Recruiting front-end editors for pitch curves",
    "加开发群联系我xxxxx": "Join the development group and contact me at xxxxx",
    "点击查看交流、问题反馈群号": "Click to view the communication and problem feedback group number",
    "xxxxx": "xxxxx",
    "加载模型": "Load model",
    "Hubert模型": "Hubert Model",
    "选择.pth文件": "Select the .pth file",
    "选择.index文件": "Select the .index file",
    "选择.npy文件": "Select the .npy file",
    "输入设备": "Input device",
    "输出设备": "Output device",
    "音频设备(请使用同种类驱动)": "Audio device (please use the same type of driver)",
    "响应阈值": "Response threshold",
    "音调设置": "Pitch settings",
    "Index Rate": "Index Rate",
    "常规设置": "General settings",
    "采样长度": "Sample length",
    "淡入淡出长度": "Fade length",
    "额外推理时长": "Extra inference time",
    "输入降噪": "Input noise reduction",
    "输出降噪": "Output noise reduction",
    "性能设置": "Performance settings",
    "开始音频转换": "Start audio conversion",
    "停止音频转换": "Stop audio conversion",
    "推理时间(ms):": "Inference time (ms):",
    "请选择pth文件": "请选择pth文件",
    "请选择index文件": "请选择index文件",
    "hubert模型路径不可包含中文": "hubert模型路径不可包含中文",
    "pth文件路径不可包含中文": "pth文件路径不可包含中文",
    "index文件路径不可包含中文": "index文件路径不可包含中文",
    "重载设备列表": "Reload device list",
    "音高算法": "pitch detection algorithm",
    "harvest进程数": "Number of CPU processes used for harvest pitch algorithm"
}
